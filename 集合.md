# 集合

## ArrayList

ArrayList的源码分析

1. jdk1.7版本

   1. 数组的初始长度默认是10：

   2. 数组的创建时机：在ArrayList初始化的时候就开始创建数组了

   3. 数组的扩容：扩容为原数组长度的1.5倍

2. jdk1.8版本与1.7的区别

   数组创建时机：添加第一个数组的时候创建

3. Vector与ArrayList的区别:
   1. 底层数组扩容长度为原数组的2倍。
   2. add方法里加有Synchronized关键字。效率低，安全。

## LinkedList

LinkedList源码

1. 双向链表
2. 理解add方法
3. get（index）方法中利用**双向链表**的特点判断index和size/2的值比较，**选择离首尾进的一头遍历**。

## 迭代器

1. Iterable、Iterator()、Iterator接口的区别：

   1. 用一张关系图来理解

      <img src="D:\BaiduSyncdisk\集合.assets\image-20220721230538224-16584159426631-16584159467053.png" alt="image-20220721230538224" style="zoom: 25%;" />

   2. ListIterator与Iterator的区别：
      1. ListIterator的优点：
         1. 可以在遍历的时候自己**添加**元素
         2. 可以让那个索引指针前后都能移动【hasNext（）、hasPrevious（）】
      2. Iterator的优点：
         1. 可以在遍历的同时自己**删除**元素。

## HashMap

> 补充hashmap面试题网址
> https://blog.csdn.net/weixin_39819661/article/details/111249224

#### 描述一下Map put的过程。

1. 得到key的hashcode，然后经过二次散列，和扰动函数的处理，再经过与数组长度-1做‘与’运算，得到数组的一个桶下标。
2. 判断桶下标所在的位置有无entry节点，如果没有的话，将key、value、hash值等分装成一个entry节点，这个节点的引用放入数组的这个位置。
3. 如果有节点，那么就进入一个循环，循环判断节点中的hash值，key值是否equals添加的键值对，如果是则覆盖，如果不是则找链表的下一个值。如果都没找到，那么就再链表最后面插入节点。jdk1.7选择头插。

### JDK7和JDK8中的HashMap有什么区别？

红黑树，7上8下

### 介绍一下HashMap底层的实现原理。

数组+链表+红黑树。使用了hash函数，扰动函数，让hash值更加散列，然后用链地址法解决hash冲突，用红黑树来提高查询效率。

### 介绍一下HashMap的扩容机制。

- 添加元素时可能发生扩容

- 扩容条件为：”元素个数>=length*0.75“ 且 ”当前添加元素所在下标的位置引用不为空“。
- 扩容为原来集合长度的2倍。
- 扩容是创建一个新数组，把数据放到到新数组（期间重新记算hash值）。

#### 如何得到一个线程安全的Map？

1. 使用Collections工具类，将线程不安全的Map包装成线程安全的Map；
2. 使用java.util.concurrent包下的Map，如ConcurrentHashMap；
3. 不建议使用Hashtable，虽然Hashtable是线程安全的，但是性能较差。

### HashMap有什么特点？

1. HashMap是线程不安全的实现；
2. HashMap可以使用null作为key或value。

### HashMap加载因子为啥设置为超过Entry数组的0.75？？？

因为0.75在时间和空间上做了一个非常好的折中。

### HashMap主数组的长度为什么必须是2^n???

1. 因为这是hash&length-1等价于hash%length的前提。没有这个保证两个式子就不可能等价。

2. 为2^n时才能让命中的下标分布均匀一些。反例，长度为9，好多hash值最后都落到了0下标位置，不均匀。

### HashMap中的循环链表是如何产生的？

**参考答案**

在多线程的情况下，当重新调整HashMap大小的时候，就会存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历。如果条件竞争发生了，那么就会产生死循环了。



###  HashMap为什么用红黑树而不用B树？

B树是一种自平衡的树，能够保持数据有序。 这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。 B树与AVL树不同，可以拥有2个以上的子节点，并且每个节点可以有多个键值，这些属性减少了定位记录时所经历的中间过程，加快了存取速度。

？？？？？？？？？？？



B/B+树多用于外存上时，B/B+也被成为一个磁盘友好的数据结构。

HashMap本来是数组+链表的形式，链表由于其查找慢的特点，所以需要被查找效率更高的树结构来替换。如果用B/B+树的话，在数据量不是很多的情况下，数据都会“挤在”一个结点里面，这个时候遍历效率就退化成了链表。



###  HashMap是如何解决哈希冲突的？

为了解决碰撞，数组中的元素是单向链表类型。当链表长度到达一个阈值（8）时(桶的数量必须大于64，小于64的时候只会扩容)，会将链表转换成红黑树提高性能。而当链表长度缩小到另一个阈值（6）时，又会将红黑树转换回单向链表提高性能。

### 说一说HashMap和HashTable的区别

1. Hashtable是一个线程安全的Map实现，但HashMap是线程不安全的实现，所以HashMap比Hashtable的性能高一点。
2. Hashtable不允许使用null作为key和value，如果试图把null值放进Hashtable中，将会引发空指针异常，但HashMap可以使用null作为key或value。
3. HashMap 进行 put 或者 get􏱤 操作，可以达到常数时间的性能；而 HashTable 的 put 和 get 操作都是加了 `synchronized` 锁的，所以效率很差。
4. 父类不同：HashMap 继承了 `AbstractMap` 类，而 HashTable 继承了 `Dictionary` 类
5. 初始容量不同：HashTable 的初始长度是11，之后每次扩充容量变为之前的 2n+1（n为上一次的长度）而 HashMap 的初始长度为16，之后每次扩充变为原来的两倍。创建时，如果给定了容量初始值，那么HashTable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小。

### HashMap与ConcurrentHashMap有什么区别？

HashMap是非线程安全的，这意味着不应该在多线程中对这些Map进行修改操作，否则会产生数据不一致的问题，甚至还会因为并发插入元素而导致链表成环，这样在查找时就会发生死循环，影响到整个应用程序。

Collections工具类可以将一个Map转换成线程安全的实现，其实也就是通过一个包装类，然后把所有功能都委托给传入的Map，而包装类是基于synchronized关键字来保证线程安全的（Hashtable也是基于synchronized关键字），底层使用的是互斥锁，性能与吞吐量比较低。

ConcurrentHashMap的实现细节远没有这么简单，因此性能也要高上许多。它没有使用一个全局锁来锁住自己，而是采用了减少锁粒度的方法，尽量减少因为竞争锁而导致的阻塞与冲突，而且ConcurrentHashMap的检索操作是不需要锁的。

### 介绍一下ConcurrentHashMap是怎么实现的？

**参考答案**

JDK 1.7中的实现：

在 jdk 1.7 中，ConcurrentHashMap 是由 Segment 数据结构和 HashEntry 数组结构构成，采取分段锁来保证安全性。Segment 是 ReentrantLock 重入锁，在 ConcurrentHashMap 中扮演锁的角色，HashEntry 则用于存储键值对数据。一个 ConcurrentHashMap里包含一个 Segment 数组，一个 Segment 里包含一个 HashEntry 数组，Segment 的结构和 HashMap 类似，是一个数组和链表结构。

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645689003626/A064CF0DD49D1B3694548913C28728DB)

JDK 1.8中的实现：

JDK1.8 的实现已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 Synchronized 和 CAS 来操作，整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本。

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645689024609/9C8ABF1CD3475339A49DE3B9E1696FE7)





ConcurrentHashMap将hash表分为16个桶（默认值），诸如get,put,remove等常用操作只锁当前需要用到的桶。试想，原来只能一个线程进入，现在却能同时16个写线程进入（写线程才需要锁定，而读线程几乎不受限制，之后会提到），并发性的提升是显而易见的。
更令人惊讶的是ConcurrentHashMap的读取并发，因为在读取的大多数时候都没有用到锁定，所以读取操作几乎是完全的并发操作，而写操作锁定的粒度又非常细，比起之前又更加快速（这一点在桶更多时表现得更明显些）。只有在求size等操作时才需要锁定整个表。

### ConcurrentHashMap是怎么分段分组的？

> 回答的是个屁

get操作：

Segment的get操作实现非常简单和高效，先经过一次再散列，然后使用这个散列值通过散列运算定位到 Segment，再通过散列算法定位到元素。get操作的高效之处在于整个get过程都不需要加锁，除非读到空的值才会加锁重读。原因就是将使用的共享变量定义成 volatile 类型。

put操作：

当执行put操作时，会经历两个步骤：

1. 判断是否需要扩容；
2. 定位到添加元素的位置，将其放入 HashEntry 数组中。

插入过程会进行第一次 key 的 hash 来定位 Segment 的位置，如果该 Segment 还没有初始化，即通过 CAS 操作进行赋值，然后进行第二次 hash 操作，找到相应的 HashEntry 的位置，这里会利用继承过来的锁的特性，在将数据插入指定的 HashEntry 位置时（尾插法），会通过继承 ReentrantLock 的 tryLock() 方法尝试去获取锁，如果获取成功就直接插入相应的位置，如果已经有线程获取该Segment的锁，那当前线程会以自旋的方式去继续的调用 tryLock() 方法去获取锁，超过指定次数就挂起，等待唤醒。

### 说一说你对LinkedHashMap的理解

LinkedHashMap使用**双向链表**来维护key-value对的顺序（其实只需要考虑key的顺序），该链表负责维护Map的迭代顺序，迭代顺序与key-value对的插入顺序保持一致。**使hashmap变得有序化。**

LinkedHashMap需要维护元素的插入顺序，因此性能略低于HashMap的性能。但因为它以链表来维护内部顺序，所以在迭代访问Map里的全部元素时将有较好的性能。

### 请介绍LinkedHashMap的底层原理

LinkedHashMap继承于HashMap，它在HashMap的基础上，通过维护一条双向链表，解决了HashMap不能随时保持遍历顺序和插入顺序一致的问题。在实现上，LinkedHashMap很多方法直接继承自HashMap，仅为维护双向链表重写了部分方法。

## TreeMap

### 请介绍TreeMap的底层原理？？

？？？？？？？





## List

### 有哪些线程安全的List？

1. Vector

   Vector是比较古老的API，虽然保证了线程安全，但是由于效率低一般不建议使用。

2. Collections.SynchronizedList

   SynchronizedList是Collections的内部类，Collections提供了synchronizedList方法，可以将一个线程不安全的List包装成线程安全的List，即SynchronizedList。它比Vector有更好的扩展性和兼容性，但是它所有的方法都带有同步锁，也不是性能最优的List。

3. CopyOnWriteArrayList

   CopyOnWriteArrayList是Java 1.5在java.util.concurrent包下增加的类，它采用复制底层数组的方式来实现写操作。当线程对此类集合执行读取操作时，线程将会直接读取集合本身，无须加锁与阻塞。当线程对此类集合执行写入操作时，集合会在底层复制一份新的数组，接下来对新的数组执行写入操作。由于对集合的写入操作都是对数组的副本执行操作，因此它是线程安全的。在所有线程安全的List中，它是性能最优的方案。

###  谈谈CopyOnWriteArrayList的原理

CopyOnWriteArrayList是Java并发包里提供的并发类，简单来说它就是一个线程安全且读操作无锁的ArrayList。正如其名字一样，在写操作时会复制一份新的List，在新的List上完成写操作，然后再将原引用指向新的List。这样就保证了写操作的线程安全。

CopyOnWriteArrayList允许线程并发访问读操作，这个时候是没有加锁限制的，性能较高。而写操作的时候，则首先将容器复制一份，然后在新的副本上执行写操作，这个时候写操作是上锁的。结束之后再将原容器的引用指向新容器。注意，在上锁执行写操作的过程中，如果有需要读操作，会作用在原容器上。因此上锁的写操作不会影响到并发访问的读操作。

- 优点：读操作性能很高，因为无需任何同步措施，比较适用于读多写少的并发场景。在遍历传统的List时，若中途有别的线程对其进行修改，则会抛出ConcurrentModificationException异常。而CopyOnWriteArrayList由于其"读写分离"的思想，遍历和修改操作分别作用在不同的List容器，所以在使用迭代器进行遍历时候，也就不会抛出ConcurrentModificationException异常了。
- 缺点：一是内存占用问题，毕竟每次执行写操作都要将原容器拷贝一份，数据量大时，对内存压力较大，可能会引起频繁GC。二是无法保证实时性，Vector对于读写操作均加锁同步，可以保证读和写的强一致性。而CopyOnWriteArrayList由于其实现策略的原因，写和读分别作用在新老不同容器上，在写操作执行过程中，读不会阻塞但读取到的却是老容器的数据。

## Set

###  说一说TreeSet和HashSet的区别

HashSet、TreeSet中的元素都是不能重复的，并且它们都是线程不安全的，二者的区别是：

1. HashSet中的元素可以是null，但TreeSet中的元素不能是null；
2. HashSet不能保证元素的排列顺序，而TreeSet支持自然排序、定制排序两种排序的方式；
3. HashSet底层是采用哈希表实现的，而TreeSet底层是采用红黑树实现的。

###  说一说HashSet的底层结构

**参考答案**

HashSet是基于HashMap实现的，默认构造函数是构建一个初始容量为16，负载因子为0.75 的HashMap。它封装了一个 HashMap 对象来存储所有的集合元素，所有放入 HashSet 中的集合元素实际上由 HashMap 的 key 来保存，而 HashMap 的 value 则存储了一个 PRESENT，它是一个静态的 Object 对象。

## Queue

#### BlockingQueue中有哪些方法，为什么这样设计？

**参考答案**

为了应对不同的业务场景，BlockingQueue 提供了4 组不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每组方法的表现是不同的。这些方法如下：

|      | 抛异常    | 特定值   | 阻塞   | 超时                 |
| :--- | :-------- | :------- | :----- | :------------------- |
| 插入 | add(e)    | offer(e) | put(e) | offer(e, time, unit) |
| 移除 | remove()  | poll()   | take() | poll(time, unit)     |
| 检查 | element() | peek()   |        |                      |

四组不同的行为方式含义如下：

- 抛异常：如果操作无法立即执行，则抛一个异常；
- 特定值：如果操作无法立即执行，则返回一个特定的值(一般是 true / false)。
- 阻塞：如果操作无法立即执行，则该方法调用将会发生阻塞，直到能够执行；
- 超时：如果操作无法立即执行，则该方法调用将会发生阻塞，直到能够执行。但等待时间不会超过给定值，并返回一个特定值以告知该操作是否成功(典型的是true / false)。

#### 2.31 BlockingQueue是怎么实现的？

**参考答案**

BlockingQueue是一个接口，它的实现类有ArrayBlockingQueue、DelayQueue、 LinkedBlockingQueue、PriorityBlockingQueue、SynchronousQueue等。它们的区别主要体现在存储结构上或对元素操作上的不同，但是对于put与take操作的原理是类似的。下面以ArrayBlockingQueue为例，来说明BlockingQueue的实现原理。

首先看一下ArrayBlockingQueue的构造函数，它初始化了put和take函数中用到的关键成员变量，这两个变量的类型分别是ReentrantLock和Condition。ReentrantLock是AbstractQueuedSynchronizer（AQS）的子类，它的newCondition函数返回的Condition实例，是定义在AQS类内部的ConditionObject类，该类可以直接调用AQS相关的函数。

```
public ArrayBlockingQueue(int capacity, boolean fair) {      if (capacity <= 0)          throw new IllegalArgumentException();      this.items = new Object[capacity];      lock = new ReentrantLock(fair);      notEmpty = lock.newCondition();      notFull = lock.newCondition();  }
```

put函数会在队列末尾添加元素，如果队列已经满了，无法添加元素的话，就一直阻塞等待到可以加入为止。函数的源码如下所示。我们会发现put函数使用了wait/notify的机制。与一般生产者-消费者的实现方式不同，同步队列使用ReentrantLock和Condition相结合的机制，即先获得锁，再等待，而不是synchronized和wait的机制。

```
public void put(E e) throws InterruptedException {      checkNotNull(e);      final ReentrantLock lock = this.lock;      lock.lockInterruptibly();      try {          while (count == items.length)              notFull.await();          enqueue(e);      } finally {          lock.unlock();      }  }
```

再来看一下消费者调用的take函数，take函数在队列为空时会被阻塞，一直到阻塞队列加入了新的元素。

```java
public E take() throws InterruptedException { 
    final ReentrantLock lock = this.lock;      
    lock.lockInterruptibly();      
    try {          
        while (count == 0)              
            notEmpty.await();          
        return dequeue();      
    } finally {          
        lock.unlock();      
    }  
}
```



